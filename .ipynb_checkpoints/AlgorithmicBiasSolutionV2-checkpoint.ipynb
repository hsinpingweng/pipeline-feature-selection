{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithmic Bias - Full Solution\n",
    "\n",
    "1. Load the Breast Cancer dataset using the code in AlgorithmBiasCore and assess the bias of classifiers trained on this dataset, i.e. are classifiers biased towards the majority class? Consider k-NN, Decision Trees, Logistic Regression and Naive Bayes in your assessment. Test for bias using hold-out testing and cross-validation. \n",
    "2. Propose a strategy to rectify this bias. Evaluate the effect of this strategy in terms of classification bias and overall accuracy. You may choose to work with hold-out testing only for this evaluation. Discuss the effectiveness of the strategy. \n",
    "3. Test the impact of this strategy on another dataset of your choice. Discuss the effectiveness of the strategy on this second dataset.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1\n",
    "\n",
    "<span style=\"color:blue\">\n",
    "Load the Breast Cancer dataset using the code in AlgorithmBiasCore and assess the bias of classifiers trained on this dataset, i.e. are classifiers biased towards the majority class? Consider k-NN, Decision Trees, Logistic Regression and Naive Bayes in your assessment. Test for bias using hold-out testing and cross-validation. \n",
    "</span>\n",
    "\n",
    "In the following analysis we compare:\n",
    "- counts of predictions of the minority class \n",
    "- actual counts of the minority class in the test set.  \n",
    "\n",
    "If the predicted count is less than the actual this is evidence of bias.  \n",
    "This is completely independent of the classifier accuracy.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.1184</td>\n",
       "      <td>0.2776</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.6</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.22</td>\n",
       "      <td>23.12</td>\n",
       "      <td>94.37</td>\n",
       "      <td>609.9</td>\n",
       "      <td>0.1075</td>\n",
       "      <td>0.2413</td>\n",
       "      <td>0.1981</td>\n",
       "      <td>0.06618</td>\n",
       "      <td>0.2384</td>\n",
       "      <td>0.07542</td>\n",
       "      <td>...</td>\n",
       "      <td>37.18</td>\n",
       "      <td>106.4</td>\n",
       "      <td>762.4</td>\n",
       "      <td>0.1533</td>\n",
       "      <td>0.9327</td>\n",
       "      <td>0.8488</td>\n",
       "      <td>0.1772</td>\n",
       "      <td>0.5166</td>\n",
       "      <td>0.14460</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.34</td>\n",
       "      <td>26.86</td>\n",
       "      <td>81.15</td>\n",
       "      <td>477.4</td>\n",
       "      <td>0.1034</td>\n",
       "      <td>0.1353</td>\n",
       "      <td>0.1085</td>\n",
       "      <td>0.04562</td>\n",
       "      <td>0.1943</td>\n",
       "      <td>0.06937</td>\n",
       "      <td>...</td>\n",
       "      <td>39.34</td>\n",
       "      <td>101.7</td>\n",
       "      <td>768.9</td>\n",
       "      <td>0.1785</td>\n",
       "      <td>0.4706</td>\n",
       "      <td>0.4425</td>\n",
       "      <td>0.1459</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.12050</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.86</td>\n",
       "      <td>23.21</td>\n",
       "      <td>100.40</td>\n",
       "      <td>671.4</td>\n",
       "      <td>0.1044</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.1697</td>\n",
       "      <td>0.08878</td>\n",
       "      <td>0.1737</td>\n",
       "      <td>0.06672</td>\n",
       "      <td>...</td>\n",
       "      <td>27.78</td>\n",
       "      <td>118.6</td>\n",
       "      <td>784.7</td>\n",
       "      <td>0.1316</td>\n",
       "      <td>0.4648</td>\n",
       "      <td>0.4589</td>\n",
       "      <td>0.1727</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.08701</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.77</td>\n",
       "      <td>22.29</td>\n",
       "      <td>90.63</td>\n",
       "      <td>588.9</td>\n",
       "      <td>0.1200</td>\n",
       "      <td>0.1267</td>\n",
       "      <td>0.1385</td>\n",
       "      <td>0.06526</td>\n",
       "      <td>0.1834</td>\n",
       "      <td>0.06877</td>\n",
       "      <td>...</td>\n",
       "      <td>34.01</td>\n",
       "      <td>111.6</td>\n",
       "      <td>806.9</td>\n",
       "      <td>0.1737</td>\n",
       "      <td>0.3122</td>\n",
       "      <td>0.3809</td>\n",
       "      <td>0.1673</td>\n",
       "      <td>0.3080</td>\n",
       "      <td>0.09333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0           0.1184   \n",
       "1        14.22         23.12           94.37      609.9           0.1075   \n",
       "2        12.34         26.86           81.15      477.4           0.1034   \n",
       "3        14.86         23.21          100.40      671.4           0.1044   \n",
       "4        13.77         22.29           90.63      588.9           0.1200   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0            0.2776          0.3001              0.14710         0.2419   \n",
       "1            0.2413          0.1981              0.06618         0.2384   \n",
       "2            0.1353          0.1085              0.04562         0.1943   \n",
       "3            0.1980          0.1697              0.08878         0.1737   \n",
       "4            0.1267          0.1385              0.06526         0.1834   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871  ...          17.33            184.6      2019.0   \n",
       "1                 0.07542  ...          37.18            106.4       762.4   \n",
       "2                 0.06937  ...          39.34            101.7       768.9   \n",
       "3                 0.06672  ...          27.78            118.6       784.7   \n",
       "4                 0.06877  ...          34.01            111.6       806.9   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1533             0.9327           0.8488                0.1772   \n",
       "2            0.1785             0.4706           0.4425                0.1459   \n",
       "3            0.1316             0.4648           0.4589                0.1727   \n",
       "4            0.1737             0.3122           0.3809                0.1673   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  target  \n",
       "0          0.4601                  0.11890       0  \n",
       "1          0.5166                  0.14460       0  \n",
       "2          0.3215                  0.12050       0  \n",
       "3          0.3000                  0.08701       0  \n",
       "4          0.3080                  0.09333       0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bcDB = datasets.load_breast_cancer()\n",
    "bcDF = pd.DataFrame(bcDB.data, columns= list(bcDB['feature_names']))\n",
    "bcDF['target'] = pd.Series(bcDB.target)\n",
    "bcDF = bcDF.sort_values(by = ['target'])\n",
    "bcDF = bcDF.reset_index(drop=True)\n",
    "bcDF.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "212 malignant\n",
      "357 benign\n"
     ]
    }
   ],
   "source": [
    "vc = bcDF['target'].value_counts()\n",
    "for i,j in enumerate(bcDB.target_names):\n",
    "    print (vc[i],j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((569, 30), (569,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = bcDF.pop('target').values\n",
    "X = bcDF.values\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((569, 30), (569,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "X, y = shuffle(X, y, random_state=1)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "model_d = {}\n",
    "\n",
    "model_d['dtree'] = DecisionTreeClassifier(criterion='entropy')\n",
    "model_d['kNN'] = KNeighborsClassifier(n_neighbors=3)  \n",
    "model_d['mnb'] = MultinomialNB()\n",
    "model_d['logistic'] = LogisticRegression(max_iter=10000, solver = 'sag', random_state=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hold-Out Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Malignant in test set : 50\n",
      "DecisionTreeClassifier Pred. Malignant: 48 Accuracy: 0.94\n",
      "KNeighborsClassifier   Pred. Malignant: 49 Accuracy: 0.92\n",
      "MultinomialNB          Pred. Malignant: 45 Accuracy: 0.92\n",
      "LogisticRegression     Pred. Malignant: 49 Accuracy: 0.92\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "bias_d = {}\n",
    "acc_bl = {}\n",
    "\n",
    "print(\"Malignant in test set : %d\" % (len(y_test) - y_test.sum()))\n",
    "\n",
    "for m in model_d:\n",
    "    y_pred = model_d[m].fit(X_train, y_train).predict(X_test)\n",
    "    pred_count = (len(y_pred) - y_pred.sum())\n",
    "    bias_d[m] = pred_count\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    acc_bl[m] = acc\n",
    "\n",
    "    print(\"{:22} Pred. Malignant: {:d} Accuracy: {:.2f}\".format(type(model_d[m]).__name__, pred_count,acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "%matplotlib inline \n",
    "\n",
    "# Add the prior figures to the data for plotting\n",
    "objects = ['Prior'] + list(bias_d.keys())\n",
    "positive = [len(y_test) - y_test.sum()] + list(bias_d.values())\n",
    "\n",
    "y_pos = np.arange(len(objects))\n",
    "\n",
    "plt.bar(y_pos, positive, align='center', color=['red', 'blue', 'blue','blue','blue'],alpha=0.5)\n",
    "plt.xticks(y_pos, objects)\n",
    "plt.ylabel('Malginant Count')\n",
    "plt.title('ML Algorithm Bias')\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hold- Out Testing Discussion\n",
    "- Assessment of bias is independent of accuracy, i.e. proportion of examples classified as the minority class compared with the actual proportion in the test set. \n",
    "- kNN and Logistic Regression not really showing bias (49 v 50).\n",
    "- Naive Bayes has bias, 45 v 50, i.e. a 10% bias. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "def tp(y_true, y_pred): return confusion_matrix(y_true, y_pred)[1, 1]\n",
    "def tn(y_true, y_pred): return confusion_matrix(y_true, y_pred)[0, 0]\n",
    "def fp(y_true, y_pred): return confusion_matrix(y_true, y_pred)[0, 1]\n",
    "def fn(y_true, y_pred): return confusion_matrix(y_true, y_pred)[1, 0]\n",
    "scoring = {'tp' : make_scorer(tp), 'tn' : make_scorer(tn),\n",
    "           'fp' : make_scorer(fp), 'fn' : make_scorer(fn)}\n",
    "\n",
    "folds = 4\n",
    "v = 0 #  use 1 or 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 x CV DecisionTreeClassifier N: 212 Pred N: 214 Acc: 0.92\n",
      "4 x CV KNeighborsClassifier   N: 212 Pred N: 203 Acc: 0.91\n",
      "4 x CV MultinomialNB          N: 212 Pred N: 176 Acc: 0.89\n",
      "4 x CV LogisticRegression     N: 212 Pred N: 195 Acc: 0.92\n"
     ]
    }
   ],
   "source": [
    "bias_cv = {}\n",
    "\n",
    "for m in model_d:\n",
    "    cv_results = cross_validate(model_d[m], X, y, cv= folds,scoring=scoring, return_train_score=False, \n",
    "                                    verbose = v, n_jobs = -1)\n",
    "    n_tot = cv_results['test_tn'].sum() + cv_results['test_fn'].sum()\n",
    "    acc = (cv_results['test_tp'].sum() + cv_results['test_tn'].sum())/len(y)\n",
    "    bias_cv[m] = n_tot\n",
    "  \n",
    "    print(\"{} x CV {:22} N: {:d} Pred N: {:d} Acc: {:.2f}\".format(folds, type(model_d[m]).__name__, \n",
    "                                                                  vc[0] , n_tot,acc)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "objects = ['Prior'] + list(bias_cv.keys())\n",
    "positive = [vc[0]] + list(bias_cv.values())\n",
    "\n",
    "y_pos = np.arange(len(objects))\n",
    "\n",
    "plt.bar(y_pos, positive, align='center', color=['red', 'blue', 'blue','blue','blue','blue'],alpha=0.5)\n",
    "plt.xticks(y_pos, objects)\n",
    "plt.ylabel('Malignant Count')\n",
    "plt.title('ML Algorithm Bias (X-val)')\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X-Val Testing Discussion\n",
    "- This assessment is more robust than Hold-Out Testing because all data is consisered. \n",
    "    - We have 212 minority class examples compared with 50 in hold-out.\n",
    "- All methods except DTrees show bias.\n",
    "- DTrees are unbiased and very accurate. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([87, 88, 84, 85])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results['test_tp']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Q2\n",
    "\n",
    "<span style=\"color:blue\">  \n",
    "Propose a strategy to rectify this bias. Evaluate the effect of this strategy in terms of classification bias and overall accuracy. You may choose to work with hold-out testing only for this evaluation. Discuss the effectiveness of the strategy.  \n",
    "</span>\n",
    "   \n",
    "### The Fix\n",
    "The Fix is to use SMOTE to upsample the minority class.  \n",
    "Briefly, SMOTE produces additional synthetic minority class samples by interpolating between real samples.  \n",
    "We configure SMOTE to bring up the minority class count level with the majority class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE, RandomOverSampler, ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.1184</td>\n",
       "      <td>0.2776</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.6</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.22</td>\n",
       "      <td>23.12</td>\n",
       "      <td>94.37</td>\n",
       "      <td>609.9</td>\n",
       "      <td>0.1075</td>\n",
       "      <td>0.2413</td>\n",
       "      <td>0.1981</td>\n",
       "      <td>0.06618</td>\n",
       "      <td>0.2384</td>\n",
       "      <td>0.07542</td>\n",
       "      <td>...</td>\n",
       "      <td>37.18</td>\n",
       "      <td>106.4</td>\n",
       "      <td>762.4</td>\n",
       "      <td>0.1533</td>\n",
       "      <td>0.9327</td>\n",
       "      <td>0.8488</td>\n",
       "      <td>0.1772</td>\n",
       "      <td>0.5166</td>\n",
       "      <td>0.14460</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.34</td>\n",
       "      <td>26.86</td>\n",
       "      <td>81.15</td>\n",
       "      <td>477.4</td>\n",
       "      <td>0.1034</td>\n",
       "      <td>0.1353</td>\n",
       "      <td>0.1085</td>\n",
       "      <td>0.04562</td>\n",
       "      <td>0.1943</td>\n",
       "      <td>0.06937</td>\n",
       "      <td>...</td>\n",
       "      <td>39.34</td>\n",
       "      <td>101.7</td>\n",
       "      <td>768.9</td>\n",
       "      <td>0.1785</td>\n",
       "      <td>0.4706</td>\n",
       "      <td>0.4425</td>\n",
       "      <td>0.1459</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.12050</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.86</td>\n",
       "      <td>23.21</td>\n",
       "      <td>100.40</td>\n",
       "      <td>671.4</td>\n",
       "      <td>0.1044</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.1697</td>\n",
       "      <td>0.08878</td>\n",
       "      <td>0.1737</td>\n",
       "      <td>0.06672</td>\n",
       "      <td>...</td>\n",
       "      <td>27.78</td>\n",
       "      <td>118.6</td>\n",
       "      <td>784.7</td>\n",
       "      <td>0.1316</td>\n",
       "      <td>0.4648</td>\n",
       "      <td>0.4589</td>\n",
       "      <td>0.1727</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.08701</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.77</td>\n",
       "      <td>22.29</td>\n",
       "      <td>90.63</td>\n",
       "      <td>588.9</td>\n",
       "      <td>0.1200</td>\n",
       "      <td>0.1267</td>\n",
       "      <td>0.1385</td>\n",
       "      <td>0.06526</td>\n",
       "      <td>0.1834</td>\n",
       "      <td>0.06877</td>\n",
       "      <td>...</td>\n",
       "      <td>34.01</td>\n",
       "      <td>111.6</td>\n",
       "      <td>806.9</td>\n",
       "      <td>0.1737</td>\n",
       "      <td>0.3122</td>\n",
       "      <td>0.3809</td>\n",
       "      <td>0.1673</td>\n",
       "      <td>0.3080</td>\n",
       "      <td>0.09333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0           0.1184   \n",
       "1        14.22         23.12           94.37      609.9           0.1075   \n",
       "2        12.34         26.86           81.15      477.4           0.1034   \n",
       "3        14.86         23.21          100.40      671.4           0.1044   \n",
       "4        13.77         22.29           90.63      588.9           0.1200   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0            0.2776          0.3001              0.14710         0.2419   \n",
       "1            0.2413          0.1981              0.06618         0.2384   \n",
       "2            0.1353          0.1085              0.04562         0.1943   \n",
       "3            0.1980          0.1697              0.08878         0.1737   \n",
       "4            0.1267          0.1385              0.06526         0.1834   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871  ...          17.33            184.6      2019.0   \n",
       "1                 0.07542  ...          37.18            106.4       762.4   \n",
       "2                 0.06937  ...          39.34            101.7       768.9   \n",
       "3                 0.06672  ...          27.78            118.6       784.7   \n",
       "4                 0.06877  ...          34.01            111.6       806.9   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1533             0.9327           0.8488                0.1772   \n",
       "2            0.1785             0.4706           0.4425                0.1459   \n",
       "3            0.1316             0.4648           0.4589                0.1727   \n",
       "4            0.1737             0.3122           0.3809                0.1673   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  target  \n",
       "0          0.4601                  0.11890       0  \n",
       "1          0.5166                  0.14460       0  \n",
       "2          0.3215                  0.12050       0  \n",
       "3          0.3000                  0.08701       0  \n",
       "4          0.3080                  0.09333       0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bcDB = datasets.load_breast_cancer()\n",
    "bcDF = pd.DataFrame(bcDB.data, columns= list(bcDB['feature_names']))\n",
    "bcDF['target'] = pd.Series(bcDB.target)\n",
    "bcDF = bcDF.sort_values(by = ['target'])\n",
    "bcDF = bcDF.reset_index(drop=True)\n",
    "bcDF.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((569, 30), (569,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = bcDF.pop('target').values\n",
    "X = bcDF.values\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upsample the minority class count so that it is level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'ratio'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-a351e0a692b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mratio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX_train_res\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/imblearn/utils/_validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    638\u001b[0m                           FutureWarning)\n\u001b[1;32m    639\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 640\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    641\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'ratio'"
     ]
    }
   ],
   "source": [
    "sm = SMOTE(random_state=12, ratio = 1.0)\n",
    "X_train_res, y_train_res = sm.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Verify that the upsampling has occured.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_train), len(y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.sum(), y_train_res.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original Training\")\n",
    "print(\"Majority class:\",y_train.sum())\n",
    "print(\"Minority class:\",len(y_train) - y_train.sum())\n",
    "print(\"Upsampled Training\")\n",
    "print(\"Majority class:\",y_train_res.sum())\n",
    "print(\"Minority class:\",len(y_train_res) - y_train_res.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Malignant in test set : %d\" % (len(y_test) - y_test.sum()))\n",
    "res_d = {}\n",
    "acc_res = {}\n",
    "\n",
    "for m in model_d:\n",
    "    y_pred = model_d[m].fit(X_train_res, y_train_res).predict(X_test)\n",
    "    pred_count = (len(y_pred) - y_pred.sum())\n",
    "    res_d[m] = pred_count\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    acc_res[m] = acc\n",
    "\n",
    "    print(\"{:22} Pred. Malignant: {:d} Accuracy: {:.2f}\".format(type(model_d[m]).__name__, pred_count,acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "%matplotlib inline \n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "width = 0.35\n",
    "\n",
    "# Add the prior figures to the data for plotting\n",
    "objects = ['Prior'] + list(bias_d.keys())\n",
    "positive = [len(y_test) - y_test.sum()] + list(bias_d.values())\n",
    "res = [len(y_test) - y_test.sum()] + list(res_d.values())\n",
    "\n",
    "y_pos = np.arange(len(objects))\n",
    "\n",
    "p1 = ax.bar(y_pos, positive, width, align='center', \n",
    "            color=['red', 'blue', 'blue','blue','blue'],alpha=0.5)\n",
    "\n",
    "p2 = ax.bar(y_pos+width, res, width, align='center', \n",
    "            color=['red', 'g','g','g','g'],alpha=0.5)\n",
    "\n",
    "ax.legend((p1[1], p2[1]), ('Raw', 'Upsampled'))\n",
    "\n",
    "plt.xticks(y_pos, objects)\n",
    "plt.ylabel('Malignant Counts')\n",
    "plt.title('Impact of Upsampling')\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "objects =  list(acc_bl.keys())\n",
    "before =   list(acc_bl.values())\n",
    "after =  list(acc_res.values())\n",
    "y_pos = np.arange(len(objects))\n",
    "p1 = ax.bar(y_pos, before, width, align='center', \n",
    "            color=['blue', 'blue','blue','blue'],alpha=0.5)\n",
    "p2 = ax.bar(y_pos+width, after, width, align='center', \n",
    "            color=['g','g','g','g'],alpha=0.5)\n",
    "ax.legend((p1[1], p2[1]), ('Raw', 'Upsampled'))\n",
    "plt.xticks(y_pos, objects)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Impact of Upsampling')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Fix - Discussion\n",
    "\n",
    "The solution we propose is to upsample the minority class data in training. \n",
    "- The solution works pretty well, across multiple runs the bias is reduced. \n",
    "- The assessment is unstable in that different runs produce different results. \n",
    "- The strategy has no impact for Multinomial Naive Bayes. \n",
    "- The impact on accuracy is minimal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3 \n",
    "## Second Dataset\n",
    "  \n",
    "\n",
    "<span style=\"color:blue\">\n",
    "Test the impact of this strategy on another dataset of your choice. Discuss the effectiveness of the strategy on this second dataset. \n",
    "</span>\n",
    "\n",
    "\n",
    "The second dataset chosen is the Hotel Reviews data.  \n",
    "The first bar chart shows that the bias is greater in this dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotel_rev_pd = pd.read_csv('HotelRevHelpfulnessV2.csv')\n",
    "hotel_rev_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = hotel_rev_pd.pop('reviewHelpfulness').values\n",
    "X = hotel_rev_pd.values\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original Dataset\")\n",
    "print(\"Minority class:\",len(y) - y.sum())\n",
    "print(\"Majority class:\",y.sum())\n",
    "print(\"Minority class: {:.2f}%\".format((len(y)-y.sum())/len(y)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=2)\n",
    "bias_ds2 = {}\n",
    "acc_bl = {}\n",
    "\n",
    "print(\"Unhelpful in test set : %d\" % (len(y_test) - y_test.sum()))\n",
    "\n",
    "for m in model_d:\n",
    "    y_pred = model_d[m].fit(X_train, y_train).predict(X_test)\n",
    "    pred_count = (len(y_pred) - y_pred.sum())\n",
    "    bias_ds2[m] = pred_count\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    acc_bl[m] = acc\n",
    "  \n",
    "\n",
    "    print(\"{:22} Pred. Unhelpful: {:d} Accuracy: {:.2f}\".\n",
    "          format(type(model_d[m]).__name__, pred_count,acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "%matplotlib inline \n",
    "\n",
    "# Add the prior figures to the data for plotting\n",
    "objects = ['Prior'] + list(bias_d.keys())\n",
    "positive = [len(y_test) - y_test.sum()] + list(bias_ds2.values())\n",
    "\n",
    "y_pos = np.arange(len(objects))\n",
    "\n",
    "plt.bar(y_pos, positive, align='center', color=['red', 'blue', 'blue','blue','blue','blue','blue'],alpha=0.5)\n",
    "plt.xticks(y_pos, objects)\n",
    "plt.ylabel('Minority Count')\n",
    "plt.title('ML Algorithm Bias')\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'ratio'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-7cbd3fd5be80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mratio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msm\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mRandomOverSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mratio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#sm  = ADASYN(random_state=1, ratio = 1.0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX_train_res\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/imblearn/utils/_validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    638\u001b[0m                           FutureWarning)\n\u001b[1;32m    639\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 640\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    641\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'ratio'"
     ]
    }
   ],
   "source": [
    "sm = SMOTE(random_state=1, ratio = 1.0)\n",
    "sm  = RandomOverSampler(random_state=1, ratio = 1.0)\n",
    "#sm  = ADASYN(random_state=1, ratio = 1.0)\n",
    "X_train_res, y_train_res = sm.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unhelpful in test set : 54\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_train_res' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-d79f34365c43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_d\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_d\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_res\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_res\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mpred_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mres_ds2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred_count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train_res' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Unhelpful in test set : %d\" % (len(y_test) - y_test.sum()))\n",
    "res_ds2 = {}\n",
    "acc_res = {}\n",
    "\n",
    "for m in model_d:\n",
    "    y_pred = model_d[m].fit(X_train_res, y_train_res).predict(X_test)\n",
    "    pred_count = (len(y_pred) - y_pred.sum())\n",
    "    res_ds2[m] = pred_count\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    acc_res[m] = acc\n",
    "\n",
    "    print(\"{:22} Pred. Unhelpful: {:d} Accuracy: {:.2f}\".\n",
    "          format(type(model_d[m]).__name__, pred_count,acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bias_ds2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-c69ff211ceb4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Add the prior figures to the data for plotting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mobjects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Prior'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mpositive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_ds2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres_ds2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bias_ds2' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAANQklEQVR4nO3cX4il9X3H8fenuxEak0aJk5DurmRb1pi90KITI6VpTUObXXuxBLxQQ6QSWKQx5FIpNLnwprkohKBmWWSR3GQvGkk2ZRMplMSCNd1Z8N8qynSlOl3BNYYUDFRWv704p51hnHWenXNmZp3v+wUD85znNzPf+TH73mfPznlSVUiStr7f2ewBJEkbw+BLUhMGX5KaMPiS1ITBl6QmDL4kNbFq8JMcSfJakmfPcz5JvptkPsnTSa6b/piSpEkNucJ/GNj3Huf3A3vGbweB700+liRp2lYNflU9BrzxHksOAN+vkSeAy5J8YloDSpKmY/sUPscO4JUlxwvjx15dvjDJQUb/CuDSSy+9/uqrr57Cl5ekPk6ePPl6Vc2s5WOnEfys8NiK92uoqsPAYYDZ2dmam5ubwpeXpD6S/OdaP3Yav6WzAOxacrwTODOFzytJmqJpBP8YcMf4t3VuBH5TVe96OkeStLlWfUonyQ+Am4ArkiwA3wI+AFBVh4DjwM3APPBb4M71GlaStHarBr+qblvlfAFfm9pEkqR14SttJakJgy9JTRh8SWrC4EtSEwZfkpow+JLUhMGXpCYMviQ1YfAlqQmDL0lNGHxJasLgS1ITBl+SmjD4ktSEwZekJgy+JDVh8CWpCYMvSU0YfElqwuBLUhMGX5KaMPiS1ITBl6QmDL4kNWHwJakJgy9JTRh8SWrC4EtSEwZfkpow+JLUhMGXpCYMviQ1YfAlqQmDL0lNGHxJamJQ8JPsS/JCkvkk965w/iNJfpLkqSSnktw5/VElSZNYNfhJtgEPAPuBvcBtSfYuW/Y14Lmquha4CfiHJJdMeVZJ0gSGXOHfAMxX1emqegs4ChxYtqaADycJ8CHgDeDcVCeVJE1kSPB3AK8sOV4YP7bU/cCngTPAM8A3quqd5Z8oycEkc0nmzp49u8aRJUlrMST4WeGxWnb8ReBJ4PeBPwLuT/J77/qgqsNVNVtVszMzMxc4qiRpEkOCvwDsWnK8k9GV/FJ3Ao/UyDzwEnD1dEaUJE3DkOCfAPYk2T3+j9hbgWPL1rwMfAEgyceBTwGnpzmoJGky21dbUFXnktwNPApsA45U1akkd43PHwLuAx5O8gyjp4DuqarX13FuSdIFWjX4AFV1HDi+7LFDS94/A/zldEeTJE2Tr7SVpCYMviQ1YfAlqQmDL0lNGHxJasLgS1ITBl+SmjD4ktSEwZekJgy+JDVh8CWpCYMvSU0YfElqwuBLUhMGX5KaMPiS1ITBl6QmDL4kNWHwJakJgy9JTRh8SWrC4EtSEwZfkpow+JLUhMGXpCYMviQ1YfAlqQmDL0lNGHxJasLgS1ITBl+SmjD4ktSEwZekJgy+JDUxKPhJ9iV5Icl8knvPs+amJE8mOZXkF9MdU5I0qe2rLUiyDXgA+AtgATiR5FhVPbdkzWXAg8C+qno5ycfWaV5J0hoNucK/AZivqtNV9RZwFDiwbM3twCNV9TJAVb023TElSZMaEvwdwCtLjhfGjy11FXB5kp8nOZnkjpU+UZKDSeaSzJ09e3ZtE0uS1mRI8LPCY7XseDtwPfBXwBeBv0ty1bs+qOpwVc1W1ezMzMwFDytJWrtVn8NndEW/a8nxTuDMCmter6o3gTeTPAZcC7w4lSklSRMbcoV/AtiTZHeSS4BbgWPL1vwY+FyS7Uk+CHwWeH66o0qSJrHqFX5VnUtyN/AosA04UlWnktw1Pn+oqp5P8jPgaeAd4KGqenY9B5ckXZhULX86fmPMzs7W3NzcpnxtSXq/SnKyqmbX8rG+0laSmjD4ktSEwZekJgy+JDVh8CWpCYMvSU0YfElqwuBLUhMGX5KaMPiS1ITBl6QmDL4kNWHwJakJgy9JTRh8SWrC4EtSEwZfkpow+JLUhMGXpCYMviQ1YfAlqQmDL0lNGHxJasLgS1ITBl+SmjD4ktSEwZekJgy+JDVh8CWpCYMvSU0YfElqwuBLUhMGX5KaMPiS1ITBl6QmBgU/yb4kLySZT3Lve6z7TJK3k9wyvRElSdOwavCTbAMeAPYDe4Hbkuw9z7pvA49Oe0hJ0uSGXOHfAMxX1emqegs4ChxYYd3XgR8Cr01xPknSlAwJ/g7glSXHC+PH/l+SHcCXgEPv9YmSHEwyl2Tu7NmzFzqrJGkCQ4KfFR6rZcffAe6pqrff6xNV1eGqmq2q2ZmZmYEjSpKmYfuANQvAriXHO4Ezy9bMAkeTAFwB3JzkXFX9aBpDSpImNyT4J4A9SXYD/wXcCty+dEFV7f6/95M8DPyTsZeki8uqwa+qc0nuZvTbN9uAI1V1Ksld4/Pv+by9JOniMOQKn6o6Dhxf9tiKoa+qv558LEnStPlKW0lqwuBLUhMGX5KaMPiS1ITBl6QmDL4kNWHwJakJgy9JTRh8SWrC4EtSEwZfkpow+JLUhMGXpCYMviQ1YfAlqQmDL0lNGHxJasLgS1ITBl+SmjD4ktSEwZekJgy+JDVh8CWpCYMvSU0YfElqwuBLUhMGX5KaMPiS1ITBl6QmDL4kNWHwJakJgy9JTRh8SWrC4EtSE4OCn2RfkheSzCe5d4XzX07y9Pjt8STXTn9USdIkVg1+km3AA8B+YC9wW5K9y5a9BPxZVV0D3AccnvagkqTJDLnCvwGYr6rTVfUWcBQ4sHRBVT1eVb8eHz4B7JzumJKkSQ0J/g7glSXHC+PHzuerwE9XOpHkYJK5JHNnz54dPqUkaWJDgp8VHqsVFyafZxT8e1Y6X1WHq2q2qmZnZmaGTylJmtj2AWsWgF1LjncCZ5YvSnIN8BCwv6p+NZ3xJEnTMuQK/wSwJ8nuJJcAtwLHli5IciXwCPCVqnpx+mNKkia16hV+VZ1LcjfwKLANOFJVp5LcNT5/CPgm8FHgwSQA56pqdv3GliRdqFSt+HT8upudna25ublN+dqS9H6V5ORaL6h9pa0kNWHwJakJgy9JTRh8SWrC4EtSEwZfkpow+JLUhMGXpCYMviQ1YfAlqQmDL0lNGHxJasLgS1ITBl+SmjD4ktSEwZekJgy+JDVh8CWpCYMvSU0YfElqwuBLUhMGX5KaMPiS1ITBl6QmDL4kNWHwJakJgy9JTRh8SWrC4EtSEwZfkpow+JLUhMGXpCYMviQ1YfAlqQmDL0lNDAp+kn1JXkgyn+TeFc4nyXfH559Oct30R5UkTWLV4CfZBjwA7Af2Arcl2bts2X5gz/jtIPC9Kc8pSZrQkCv8G4D5qjpdVW8BR4EDy9YcAL5fI08AlyX5xJRnlSRNYPuANTuAV5YcLwCfHbBmB/Dq0kVJDjL6FwDA/yR59oKm3bquAF7f7CEuEu7FIvdikXux6FNr/cAhwc8Kj9Ua1lBVh4HDAEnmqmp2wNff8tyLRe7FIvdikXuxKMncWj92yFM6C8CuJcc7gTNrWCNJ2kRDgn8C2JNkd5JLgFuBY8vWHAPuGP+2zo3Ab6rq1eWfSJK0eVZ9SqeqziW5G3gU2AYcqapTSe4anz8EHAduBuaB3wJ3Dvjah9c89dbjXixyLxa5F4vci0Vr3otUveupdknSFuQrbSWpCYMvSU2se/C9LcOiAXvx5fEePJ3k8STXbsacG2G1vViy7jNJ3k5yy0bOt5GG7EWSm5I8meRUkl9s9IwbZcCfkY8k+UmSp8Z7MeT/C993khxJ8tr5Xqu05m5W1bq9MfpP3v8A/gC4BHgK2Ltszc3ATxn9Lv+NwC/Xc6bNehu4F38MXD5+f3/nvViy7l8Y/VLALZs99yb+XFwGPAdcOT7+2GbPvYl78bfAt8fvzwBvAJds9uzrsBd/ClwHPHue82vq5npf4XtbhkWr7kVVPV5Vvx4fPsHo9Qxb0ZCfC4CvAz8EXtvI4TbYkL24HXikql4GqKqtuh9D9qKADycJ8CFGwT+3sWOuv6p6jNH3dj5r6uZ6B/98t1y40DVbwYV+n19l9Df4VrTqXiTZAXwJOLSBc22GIT8XVwGXJ/l5kpNJ7tiw6TbWkL24H/g0oxd2PgN8o6re2ZjxLipr6uaQWytMYmq3ZdgCBn+fST7PKPh/sq4TbZ4he/Ed4J6qent0MbdlDdmL7cD1wBeA3wX+LckTVfXieg+3wYbsxReBJ4E/B/4Q+Ock/1pV/73Os11s1tTN9Q6+t2VYNOj7THIN8BCwv6p+tUGzbbQhezELHB3H/grg5iTnqupHGzLhxhn6Z+T1qnoTeDPJY8C1wFYL/pC9uBP4+xo9kT2f5CXgauDfN2bEi8aaurneT+l4W4ZFq+5FkiuBR4CvbMGrt6VW3Yuq2l1Vn6yqTwL/CPzNFow9DPsz8mPgc0m2J/kgo7vVPr/Bc26EIXvxMqN/6ZDk44zuHHl6Q6e8OKypm+t6hV/rd1uG952Be/FN4KPAg+Mr23O1Be8QOHAvWhiyF1X1fJKfAU8D7wAPVdWWu7X4wJ+L+4CHkzzD6GmNe6pqy902OckPgJuAK5IsAN8CPgCTddNbK0hSE77SVpKaMPiS1ITBl6QmDL4kNWHwJakJgy9JTRh8SWrifwHXe3WluIZOawAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "%matplotlib inline \n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "width = 0.35\n",
    "\n",
    "# Add the prior figures to the data for plotting\n",
    "objects = ['Prior'] + list(bias_d.keys())\n",
    "positive = [len(y_test) - y_test.sum()] + list(bias_ds2.values())\n",
    "res = [len(y_test) - y_test.sum()] + list(res_ds2.values())\n",
    "\n",
    "y_pos = np.arange(len(objects))\n",
    "\n",
    "p1 = ax.bar(y_pos, positive, width, align='center', \n",
    "            color=['red', 'blue', 'blue','blue','blue'],alpha=0.5)\n",
    "\n",
    "p2 = ax.bar(y_pos+width, res, width, align='center', \n",
    "            color=['red', 'g','g','g','g'],alpha=0.5)\n",
    "\n",
    "ax.legend((p1[1], p2[1]), ('Raw', 'Upsampled'))\n",
    "\n",
    "plt.xticks(y_pos, objects)\n",
    "plt.ylabel('Count')\n",
    "plt.title('ML Algorithm Bias')\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shape mismatch: objects cannot be broadcast to a single shape",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-6b5a8609993d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m             color=['blue', 'blue','blue','blue'],alpha=0.5)\n\u001b[1;32m      9\u001b[0m p2 = ax.bar(y_pos+width, after, width, align='center', \n\u001b[0;32m---> 10\u001b[0;31m             color=['g','g','g','g'],alpha=0.5)\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'Raw'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Upsampled'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobjects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1436\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1438\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1440\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mbar\u001b[0;34m(self, x, height, width, bottom, align, **kwargs)\u001b[0m\n\u001b[1;32m   2430\u001b[0m         x, height, width, y, linewidth = np.broadcast_arrays(\n\u001b[1;32m   2431\u001b[0m             \u001b[0;31m# Make args iterable too.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2432\u001b[0;31m             np.atleast_1d(x), height, width, y, linewidth)\n\u001b[0m\u001b[1;32m   2433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2434\u001b[0m         \u001b[0;31m# Now that units have been converted, set the tick locations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mbroadcast_arrays\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/numpy/lib/stride_tricks.py\u001b[0m in \u001b[0;36mbroadcast_arrays\u001b[0;34m(subok, *args)\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubok\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_m\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m     \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_broadcast_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/numpy/lib/stride_tricks.py\u001b[0m in \u001b[0;36m_broadcast_shape\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;31m# use the old-iterator because np.nditer does not handle size 0 arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;31m# consistently\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m     \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m     \u001b[0;31m# unfortunately, it cannot handle 32 or more arguments directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mpos\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m31\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shape mismatch: objects cannot be broadcast to a single shape"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAMdklEQVR4nO3df6jd913H8edrSYtKpxVz1ZpkJkI2jbLOes0qolb8saT+EYT+kU46LJZQMTL/axGck/2jDEVknSHMMAUxCKszltQi4hwyNnM7+iurKdcM25hBbzfd3BRKurd/3FO5np7c873tyb3nvvd8wIXzPd/PveedT8uz35xzz2mqCknS9vemrR5AkjQbBl2SmjDoktSEQZekJgy6JDWxc6seeNeuXbVv376tenhJ2pYef/zxl6pqYdK5LQv6vn37WFpa2qqHl6RtKcm/XeucT7lIUhMGXZKaMOiS1IRBl6QmDLokNWHQJakJgy5JTRh0SWrCoEtSE1v2TtE34v3v/8Z+fEmaxCt0SWrCoEtSEwZdkprYls+ha/Ns9esFW/34m2mr/6xb/fibaav/rNfr8b1Cl6QmDLokNWHQJakJgy5JTRh0SWrCoEtSEwZdkpow6JLUhEGXpCYMuiQ1YdAlqQmDLklNGHRJasKgS1ITBl2SmjDoktSEQZekJgy6JDVh0CWpCYMuSU0YdElqwqBLUhMGXZKaGBT0JIeTXEyynOTBCee/LcnfJHkyyYUk985+VEnSeqYGPckO4CHgCHAQuDvJwbFlvwZ8rqpuBe4Afj/JjTOeVZK0jiFX6IeA5aq6VFUvA2eAo2NrCnhzkgA3AV8Crs50UknSuoYEfTfwwprjy6P71voQ8APAFeBp4L1V9fXxH5TkeJKlJEsrKyuvc2RJ0iRDgp4J99XY8buAJ4DvAd4BfCjJt77mm6pOVdViVS0uLCxscFRJ0nqGBP0ysHfN8R5Wr8TXuhd4uFYtA58Hvn82I0qShhgS9PPAgST7Ry90HgPOjq15HvgZgCTfBbwNuDTLQSVJ69s5bUFVXU1yAngM2AGcrqoLSe4fnT8JfAD4aJKnWX2K5oGqeuk6zi1JGjM16ABVdQ44N3bfyTW3rwA/P9vRJEkb4TtFJakJgy5JTRh0SWrCoEtSEwZdkpow6JLUhEGXpCYMuiQ1YdAlqQmDLklNGHRJasKgS1ITBl2SmjDoktSEQZekJgy6JDVh0CWpCYMuSU0YdElqwqBLUhMGXZKaMOiS1IRBl6QmDLokNWHQJakJgy5JTRh0SWrCoEtSEwZdkpow6JLUhEGXpCYMuiQ1YdAlqQmDLklNGHRJamJQ0JMcTnIxyXKSB6+x5o4kTyS5kOQfZzumJGmandMWJNkBPAT8HHAZOJ/kbFV9bs2am4EPA4er6vkk33md5pUkXcOQK/RDwHJVXaqql4EzwNGxNe8GHq6q5wGq6sXZjilJmmZI0HcDL6w5vjy6b623At+e5BNJHk/ynkk/KMnxJEtJllZWVl7fxJKkiYYEPRPuq7HjncCPAL8AvAv4rSRvfc03VZ2qqsWqWlxYWNjwsJKka5v6HDqrV+R71xzvAa5MWPNSVX0N+FqSTwK3As/NZEpJ0lRDrtDPAweS7E9yI3AMODu25q+Bn0iyM8m3AO8Enp3tqJKk9Uy9Qq+qq0lOAI8BO4DTVXUhyf2j8yer6tkkfws8BXwd+EhVPXM9B5ck/X9DnnKhqs4B58buOzl2/EHgg7MbTZK0Eb5TVJKaMOiS1IRBl6QmDLokNWHQJakJgy5JTRh0SWrCoEtSEwZdkpow6JLUhEGXpCYMuiQ1YdAlqQmDLklNGHRJasKgS1ITBl2SmjDoktSEQZekJgy6JDVh0CWpCYMuSU0YdElqwqBLUhMGXZKaMOiS1IRBl6QmDLokNWHQJakJgy5JTRh0SWrCoEtSEwZdkpow6JLUhEGXpCYGBT3J4SQXkywneXCddT+a5JUkd81uREnSEFODnmQH8BBwBDgI3J3k4DXW/R7w2KyHlCRNN+QK/RCwXFWXqupl4AxwdMK6Xwc+Brw4w/kkSQMNCfpu4IU1x5dH9/2fJLuBXwROrveDkhxPspRkaWVlZaOzSpLWMSTomXBfjR3/IfBAVb2y3g+qqlNVtVhViwsLCwNHlCQNsXPAmsvA3jXHe4ArY2sWgTNJAHYBdya5WlUfn8WQkqTphgT9PHAgyX7g34FjwLvXLqiq/a/eTvJR4BFjLkmba2rQq+pqkhOs/vbKDuB0VV1Icv/o/LrPm0uSNseQK3Sq6hxwbuy+iSGvql9+42NJkjbKd4pKUhMGXZKaMOiS1IRBl6QmDLokNWHQJakJgy5JTRh0SWrCoEtSEwZdkpow6JLUhEGXpCYMuiQ1YdAlqQmDLklNGHRJasKgS1ITBl2SmjDoktSEQZekJgy6JDVh0CWpCYMuSU0YdElqwqBLUhMGXZKaMOiS1IRBl6QmDLokNWHQJakJgy5JTRh0SWrCoEtSEwZdkpow6JLUxKCgJzmc5GKS5SQPTjj/S0meGn19Ksmtsx9VkrSeqUFPsgN4CDgCHATuTnJwbNnngZ+qqrcDHwBOzXpQSdL6hlyhHwKWq+pSVb0MnAGOrl1QVZ+qqv8YHX4a2DPbMSVJ0wwJ+m7ghTXHl0f3XcuvAI9OOpHkeJKlJEsrKyvDp5QkTTUk6JlwX01cmPw0q0F/YNL5qjpVVYtVtbiwsDB8SknSVDsHrLkM7F1zvAe4Mr4oyduBjwBHquqLsxlPkjTUkCv088CBJPuT3AgcA86uXZDkLcDDwD1V9dzsx5QkTTP1Cr2qriY5ATwG7ABOV9WFJPePzp8E3gd8B/DhJABXq2rx+o0tSRo35CkXquoccG7svpNrbt8H3Dfb0SRJG+E7RSWpCYMuSU0YdElqwqBLUhMGXZKaMOiS1IRBl6QmDLokNWHQJakJgy5JTRh0SWrCoEtSEwZdkpow6JLUhEGXpCYMuiQ1YdAlqQmDLklNGHRJasKgS1ITBl2SmjDoktSEQZekJgy6JDVh0CWpCYMuSU0YdElqwqBLUhMGXZKaMOiS1IRBl6QmDLokNWHQJakJgy5JTRh0SWpiUNCTHE5yMclykgcnnE+SPxqdfyrJbbMfVZK0nqlBT7IDeAg4AhwE7k5ycGzZEeDA6Os48McznlOSNMWQK/RDwHJVXaqql4EzwNGxNUeBP6tVnwZuTnLLjGeVJK0jVbX+guQu4HBV3Tc6vgd4Z1WdWLPmEeB3q+qfRsd/DzxQVUtjP+s4q1fwAG8DLs7qD7JBu4CXtuix34jtOPd2nBm259zOvHm2cu7vraqFSSd2DvjmTLhv/L8CQ9ZQVaeAUwMe87pKslRVi1s9x0Ztx7m348ywPed25s0zr3MPecrlMrB3zfEe4MrrWCNJuo6GBP08cCDJ/iQ3AseAs2NrzgLvGf22y+3Al6vqCzOeVZK0jqlPuVTV1SQngMeAHcDpqrqQ5P7R+ZPAOeBOYBn4b+De6zfyTGz50z6v03acezvODNtzbmfePHM599QXRSVJ24PvFJWkJgy6JDXROujb8SMLBsx8R5IvJ3li9PW+rZhzbKbTSV5M8sw1zs/dPsOguedxr/cm+Yckzya5kOS9E9bM1X4PnHke9/qbkvxzkidHc//OhDVztddUVcsvVl/A/Vfg+4AbgSeBg2Nr7gQeZfX36G8HPrMNZr4DeGSr93dspp8EbgOeucb5udrnDcw9j3t9C3Db6Pabgee2wb/XQ2aex70OcNPo9g3AZ4Db53mvO1+hb8ePLBgy89ypqk8CX1pnybztMzBo7rlTVV+oqs+Obv8X8Cywe2zZXO33wJnnzmj/vjo6vGH0Nf5bJHO1152Dvht4Yc3xZV77L9GQNZtp6Dw/Nvpr4KNJfnBzRntD5m2fN2Ju9zrJPuCHWb1yXGtu93udmWEO9zrJjiRPAC8Cf1dVc73XQ976v13N7CMLNtGQeT7L6mc5fDXJncDHWf2Uy3k2b/s81NzudZKbgI8Bv1FVXxk/PeFbtny/p8w8l3tdVa8A70hyM/BXSX6oqta+5jJXe935Cn07fmTB1Hmq6iuv/jWwqs4BNyTZtXkjvi7zts+DzOteJ7mB1TD+eVU9PGHJ3O33tJnnda9fVVX/CXwCODx2aq72unPQt+NHFkydOcl3J8no9iFW/xl+cdMn3Zh52+dB5nGvR/P8CfBsVf3BNZbN1X4PmXlO93phdGVOkm8Gfhb4l7Flc7XXbZ9yqW34kQUDZ74L+NUkV4H/AY7V6OX2rZLkL1j9LYVdSS4Dv83qC0hzuc+vGjD33O018OPAPcDTo+d2AX4TeAvM7X4PmXke9/oW4E+z+j/5eRPwl1X1yDw3xLf+S1ITnZ9ykaRvKAZdkpow6JLUhEGXpCYMuiQ1YdAlqQmDLklN/C8F73q58oao7wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "objects =  list(acc_bl.keys())\n",
    "before =   list(acc_bl.values())\n",
    "after =  list(acc_res.values())\n",
    "y_pos = np.arange(len(objects))\n",
    "p1 = ax.bar(y_pos, before, width, align='center', \n",
    "            color=['blue', 'blue','blue','blue'],alpha=0.5)\n",
    "p2 = ax.bar(y_pos+width, after, width, align='center', \n",
    "            color=['g','g','g','g'],alpha=0.5)\n",
    "ax.legend((p1[1], p2[1]), ('Raw', 'Upsampled'))\n",
    "plt.xticks(y_pos, objects)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Impact of Upsampling')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Dataset Discussion  \n",
    "The results on the second dataset are again quite positive. \n",
    "- With the exception of Naive Bayes, there is good improvement on bias.\n",
    "- With the exception of Logistic Regression there is not too much impact on accuracy. \n",
    "- It seems that kNN offers the best balance between bias and accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
